{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fa398b",
   "metadata": {},
   "source": [
    "# Entity Recognition \n",
    "**Entity recognition**, also known as entity extraction or entity linking, refers to the process of identifying and categorizing specific entities within text. Entities can be any well-defined objects, such as people, organizations, locations, dates, numerical expressions, or other named or generic entities of interest.\n",
    "\n",
    "The main objective of entity recognition is to extract meaningful information from unstructured text and link it to known or predefined categories. This enables the organization and analysis of textual data, supporting various downstream applications such as information retrieval, knowledge graph construction, recommendation systems, and more.\n",
    "\n",
    "Entity recognition involves the following steps:\n",
    "\n",
    "1. *Tokenization*: The text is divided into individual tokens, typically words, to provide the basic units of analysis.\n",
    "\n",
    "2. *Part-of-speech (POS) Tagging*: Each token is assigned a POS tag, which represents the grammatical role of the word (noun, verb, adjective, etc.). POS tags provide contextual information that can assist in entity recognition.\n",
    "\n",
    "3. *Entity Recognition*: This is the core step where the NLP model identifies and classifies entities within the text. The model analyzes the tokens and their contextual information to determine if a token represents an entity and assigns it a specific label or category. The labels can include commonly recognized entities such as PERSON, ORGANIZATION, LOCATION, DATE, TIME, MONEY, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d611945",
   "metadata": {},
   "source": [
    "Entity recognition can be approached using different techniques:\n",
    "\n",
    "Rule-based approach: This approach involves designing and applying handcrafted rules or patterns to identify and classify entities based on specific linguistic patterns, lexical features, or syntactic structures. For example, a rule might state that a token following the word \"President\" is likely to be a person's name. Rule-based systems require manual effort to create and maintain rules, but they can be effective for specific domains or languages with well-defined patterns.\n",
    "\n",
    "Statistical/machine learning approach: This approach involves training models using annotated data, where human annotators mark the entities in the text with their corresponding labels. Techniques like Conditional Random Fields (CRF), Hidden Markov Models (HMM), or more advanced methods such as Recurrent Neural Networks (RNNs) and Transformer-based architectures can be used to learn patterns and features from the annotated data and make predictions on new, unseen text.\n",
    "\n",
    "Entity recognition models are trained using labeled datasets, where entities are manually annotated or leveraged from existing labeled resources. These models learn to recognize patterns, context, and linguistic features associated with different types of entities, allowing them to make predictions on unseen text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c756aa4",
   "metadata": {},
   "source": [
    "Evaluation of entity recognition systems is commonly done using metrics like precision, recall, and F1-score, which measure the accuracy and completeness of the predicted entities compared to the reference annotations.\n",
    "\n",
    "Entity recognition is a fundamental task in NLP, as it helps in extracting and structuring important information from text, enabling further analysis and understanding of textual data in various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec105ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8842dc",
   "metadata": {},
   "source": [
    "Similar to other notebooks, we'll levearge the `spaCy` library. `spaCy` has some pretty stellar built in tools for entity recognition. In addition to `spaCy`, for this exampe we'll be doing entity recognition (ER) on a simple news article about the Boston Marathon. We'll be using the `BeautifulSoup` library to scrap the article and bring it into memory for parsing and entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee15862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     ---------------------------------------- 0.2/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "      --------------------------------------- 0.3/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.9/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.2/12.8 MB 3.5 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.2/12.8 MB 3.6 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.3/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.7/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.0/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.0/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.3/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.9/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.4/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.3/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (57.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\kaila\\tensorprojects\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en\n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68034c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model \n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713a4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in the article using BeautifulSoup\n",
    "url = \"https://www.outsideonline.com/health/running/gear/tech/the-boston-marathon-in-data/\"\n",
    "\n",
    "html_content = requests.get(url).text\n",
    "soup = BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56fd193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of content list : 75\n"
     ]
    }
   ],
   "source": [
    "# Parse the body of text for only relevant information \n",
    "body = soup.body.text\n",
    "body = body.split('\\n\\n')\n",
    "body = [a.strip() for a in body if a]\n",
    "print(\"Length of content list :\",len(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca2c6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Winter Gear GuideTwitter IconEnjoy coverage of racing, history, food, culture, travel, and tech with access to unlimited digital content from Outside Network's iconic brands.\\nLearn MoreBeta MTB\\nFastest Known Time\\nPinkbike\\nTrailforks\\nTrail Runner\\nTriathlete\\nVelo\\nWomen's Running\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_body = body[20] + body[40] + body[60] + body[70]\n",
    "ner_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345696d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Winter Gear\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GuideTwitter IconEnjoy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " coverage of racing, history, food, culture, travel, and tech with access to unlimited digital content from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Outside Network's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " iconic brands.<br>Learn MoreBeta MTB<br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fastest Known Time\n",
       "Pinkbike\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "<br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trailforks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "<br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trail Runner\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "<br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Triathlete\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "<br>Velo<br>Women's Running</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the spaCy model and display the results \n",
    "result = NER(ner_body)\n",
    "displacy.render(result,style=\"ent\",jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
