{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c9ae20",
   "metadata": {},
   "source": [
    "# Text Summarization \n",
    "**Text summarization** refers to the process of generating a concise and coherent summary of a longer text while preserving its key information and main ideas. It involves reducing the length of the original text while retaining the essential content and meaning.\n",
    "\n",
    "Text summarization can be classified into two main categories:\n",
    "\n",
    "1. **Extractive Summarization**: Extractive summarization involves identifying and selecting important sentences or phrases from the original text and assembling them to form a summary. The selected sentences are typically the ones that contain crucial information, such as key terms, facts, or opinions. Extractive summarization does not generate new sentences but instead extracts and rearranges the existing content.\n",
    "\n",
    "2. **Abstractive Summarization**: Abstractive summarization aims to generate a summary that may contain words, phrases, or sentences not present in the original text. It involves understanding the meaning and context of the text and generating new sentences that capture the essence of the original content. Abstractive summarization often requires advanced natural language processing techniques, such as language generation models or neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618beac3",
   "metadata": {},
   "source": [
    "Text summarization has several applications:\n",
    "\n",
    "- Information Retrieval: Summaries provide condensed versions of documents, making it easier for users to quickly assess the relevance and key points of a document before delving deeper.\n",
    "\n",
    "- News and Article Summarization: News agencies and content platforms often use summarization techniques to generate short summaries of news articles, blog posts, or other textual content to engage readers and provide a quick overview.\n",
    "\n",
    "- Document Summarization: For lengthy documents or reports, summarization can save time and effort by providing concise summaries that capture the main ideas and important details.\n",
    "\n",
    "- Meeting or Conversation Summarization: In corporate or professional settings, text summarization can be used to generate summaries of meeting transcripts or chat conversations, allowing participants to review key discussions and decisions efficiently.\n",
    "\n",
    "- Social Media and Online Reviews: On social media platforms or review websites, summarization techniques can be employed to generate brief overviews or snippets of user-generated content to provide users with quick insights or recommendations.\n",
    "\n",
    "\n",
    "The below sample is adapted from [here](https://www.kaggle.com/code/itsmohammadshahid/nlp-text-summarizer-using-spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b091214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50336a",
   "metadata": {},
   "source": [
    "In order to use various spacy models, you'll need to download them. Please run the following snippets of code in your local terminal app to download the models:\n",
    "- `python -m spacy download en_core_web_sm`\n",
    "- `python3 -m spacy download en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the english language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085163e",
   "metadata": {},
   "source": [
    "We'll use this short blurb about MSFTs Intelligent Cloud Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf796485",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\"In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has \n",
    "been lanched to empower the next generation of students with AI-ready skills. Envisioned as a three-year \n",
    "collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, \n",
    "course content and curriculum, developer support, development tools and give students access to cloud and \n",
    "AI services. As part of the program, the Redmond giant which wants to expand its reach and is planning to \n",
    "build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT \n",
    "Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as \n",
    "Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, \n",
    "Country General Manager-PS, Health and Education, Microsoft India, said, With AI being the defining technology\n",
    "of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. \n",
    "This will require more collaborations and training and working with AI. Thatâ€™s why it has become more critical \n",
    "than ever for educational institutions to integrate new cloud and AI technologies. The program is an attempt \n",
    "to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of \n",
    "tomorrow. The program aims to build up the cognitive skills and in-depth understanding of developing \n",
    "intelligent cloud connected solutions for applications across industry. Earlier in April this year, \n",
    "the company announced Microsoft Professional Program In AI as a learning track open to the public. \n",
    "The program was developed to provide job ready skills to programmers who wanted to hone their skills \n",
    "in AI and data science with a series of online courses which featured hands-on labs and expert instructors \n",
    "as well. This program also included developer-focused AI school that provided a bunch of assets to help\n",
    "build AI skills.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The score of each word is kept in a frequency table\n",
    "tokens = [token.text for token in doc]\n",
    "percentage = 0.2\n",
    "freq_of_word = dict()\n",
    "\n",
    "# Text cleaning and vectorization \n",
    "for word in doc:\n",
    "    if word.text.lower() not in list(STOP_WORDS):\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in freq_of_word.keys():\n",
    "                freq_of_word[word.text] = 1\n",
    "            else:\n",
    "                freq_of_word[word.text] += 1\n",
    "\n",
    "# Maximum frequency of word\n",
    "max_freq = max(freq_of_word.values())\n",
    "\n",
    "# Normalization of word frequency\n",
    "for word in freq_of_word.keys():\n",
    "    freq_of_word[word]=freq_of_word[word]/max_freq\n",
    "    \n",
    "# In this part, each sentence is weighed based on how often it contains the token.\n",
    "sent_tokens = [sent for sent in doc.sents]\n",
    "sent_scores = dict()\n",
    "for sent in sent_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in freq_of_word.keys():\n",
    "            if sent not in sent_scores.keys():                            \n",
    "                sent_scores[sent]=freq_of_word[word.text.lower()]\n",
    "            else:\n",
    "                sent_scores[sent]+=freq_of_word[word.text.lower()]\n",
    "\n",
    "\n",
    "len_tokens = int(len(sent_tokens)*percentage)\n",
    "\n",
    "# Summary for the sentences with maximum score. Here, each sentence in the list is of spacy.span type\n",
    "summary = nlargest(n = len_tokens, iterable = sent_scores,key=sent_scores.get)\n",
    "\n",
    "# Prepare for final summary\n",
    "final_summary = [word.text for word in summary]\n",
    "\n",
    "#convert to a string\n",
    "summary =\" \".join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A summary of the text generated by spaCy: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4f31e",
   "metadata": {},
   "source": [
    "In addition to `spaCy`, other frameworks like `NLTK`, `genism`, and `transformers` (from `HuggingFace`) can be used for text summarization "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
