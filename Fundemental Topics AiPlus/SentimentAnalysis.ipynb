{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1beb76f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis \n",
    "\n",
    "**Sentiment analysis**, also known as opinion mining, is a natural language processing (NLP) technique used to determine the sentiment or emotional tone expressed in a piece of text. It aims to classify the sentiment of a document, sentence, or even individual words as positive, negative, or neutral.\n",
    "\n",
    "The process of sentiment analysis involves several steps. First, the text data is preprocessed, which includes tasks like tokenization, removing stopwords, and normalizing words. Next, the sentiment analysis algorithm analyzes the text to identify sentiment-bearing words and phrases.\n",
    "\n",
    "There are different approaches to sentiment analysis, including:\n",
    "\n",
    "- Lexicon-based: Lexicon-based methods rely on sentiment lexicons or dictionaries that associate words with sentiment scores. Each word is assigned a polarity value, and the sentiment of a text is calculated based on the aggregated scores of the words it contains.\n",
    "\n",
    "- Machine learning-based: Machine learning techniques use labeled training data to train a model that can predict the sentiment of new, unseen text. This involves feature extraction, where numerical features are derived from the text, and classification algorithms, such as support vector machines (SVM) or recurrent neural networks (RNN), are used to classify the sentiment.\n",
    "\n",
    "- Hybrid approaches: Hybrid approaches combine lexicon-based methods with machine learning techniques to leverage the strengths of both. For example, lexicons can be used to bootstrap the sentiment classification process, and machine learning models can be fine-tuned using the labeled data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df9392",
   "metadata": {},
   "source": [
    "Note that this noteboko is adapted from [this](https://towardsdatascience.com/a-beginners-guide-to-sentiment-analysis-in-python-95e354ea84f6) example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "color = sns.color_palette()\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c30fc",
   "metadata": {},
   "source": [
    "For this analysis, we'll be looking at reviews of Amazon Products. The data consists of a `ProductId`, `UserId`, `ProfileName`, `HelpfulnesNumerator`, `HelpfulnessDenominator`, `Score`, `Time`, `Summary`, and `Text`, however we'll only be using a couple columns for this sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21ef0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentimentt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>Delight says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price  There was a wide...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id   ProductId          UserId  \\\n",
       "0           0   1  B001E4KFG0  A3SGXH7AUHU8GW   \n",
       "1           1   2  B00813GRG4  A1D87F6ZCVE5NK   \n",
       "2           2   3  B000LQOCH0   ABXLMWJIXXAIN   \n",
       "3           3   4  B000UA0QIQ  A395BORC6FGVXV   \n",
       "4           4   5  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
       "\n",
       "                       ProfileName  HelpfulnessNumerator  \\\n",
       "0                       delmartian                     1   \n",
       "1                           dll pa                     0   \n",
       "2  Natalia Corres \"Natalia Corres\"                     1   \n",
       "3                             Karl                     3   \n",
       "4    Michael D. Bigham \"M. Wassir\"                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "2                       1      4  1219017600    Delight says it all   \n",
       "3                       3      2  1307923200         Cough Medicine   \n",
       "4                       0      5  1350777600            Great taffy   \n",
       "\n",
       "                                                Text  sentiment sentimentt  \n",
       "0  I have bought several of the Vitality canned d...          1   positive  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...         -1   negative  \n",
       "2  This is a confection that has been around a fe...          1   positive  \n",
       "3  If you are looking for the secret ingredient i...         -1   negative  \n",
       "4  Great taffy at a great price  There was a wide...          1   positive  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/supplementary_content/Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d931f",
   "metadata": {},
   "source": [
    "After reading in the data using `pandas`, we can do some quick analysis to look at the distribution of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data discovery on product scores \n",
    "fig = px.histogram(df, x=\"Score\")\n",
    "fig.update_traces(marker_color=\"turquoise\",marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5)\n",
    "fig.update_layout(title_text='Product Score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb89635",
   "metadata": {},
   "source": [
    "Looks like majority of the products have a rating of `4` or `5`. For the sentiment analysis, we'll need to create labels. For this example, we'll say anything less than a 3 will be a negative sentiment, denoted by a `-1` and anything 3 or high will be a positive sentiment denoted with a `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae267f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lables \n",
    "df = df[df['Score'] != 3]\n",
    "df['sentiment'] = df['Score'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae05c89",
   "metadata": {},
   "source": [
    "Now that we've created lables, let's do some additional exploratory analysis with these lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by sentiment \n",
    "positive = df[df['sentiment'] == 1]\n",
    "negative = df[df['sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data by sentiment \n",
    "df['sentimentt'] = df['sentiment'].replace({-1 : 'negative'})\n",
    "df['sentimentt'] = df['sentimentt'].replace({1 : 'positive'})\n",
    "fig = px.histogram(df, x=\"sentimentt\")\n",
    "fig.update_traces(marker_color=\"indianred\",marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5)\n",
    "fig.update_layout(title_text='Product Sentiment')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a17f89",
   "metadata": {},
   "source": [
    "Moving on from EDA, we'll do some light cleaning of the text and summary to prepare it for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data, remove punctuation \n",
    "def remove_punctuation(text):\n",
    "    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\",  \"!\",'\"'))\n",
    "    return final\n",
    "df['Text'] = df['Text'].apply(remove_punctuation)\n",
    "df = df.dropna(subset=['Summary'])\n",
    "df['Summary'] = df['Summary'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_df = df[['Summary','sentiment']]\n",
    "featurized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb673c83",
   "metadata": {},
   "source": [
    "Now that labels have been created and data is cleaned we'll move on to splitting the data into a training set and applying a `CountVectorizer` to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(featurized_df[\"Summary\"], \n",
    "                                                    featurized_df[\"sentiment\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764168d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep for count vectorizer \n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "train_matrix = vectorizer.fit_transform(X_train)\n",
    "test_matrix = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1cb7e2",
   "metadata": {},
   "source": [
    "Now that we have embeddings, we'll just use a basic `LogisticRegression` to predict if a sentiment is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113291eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc8fd1",
   "metadata": {},
   "source": [
    "After the model is trained, we'll use it to generate predictions on our test set. With those predictions, we'll use the `classification_report` and `plot_confusion_matrix` to investigate the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the classification report \n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(lr, test_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94682a4b",
   "metadata": {},
   "source": [
    "Based on the evaulation metrics, the mode does a pretty good job at predicting positive sentiment, but it's not as accurate in predicting negative sentiment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
